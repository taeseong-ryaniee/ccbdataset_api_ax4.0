#!/usr/bin/env python3
"""
A.X 4.0 API ì—ì´ì „íŠ¸ - SKT A.X API ê¸°ë°˜ Q&A ìƒì„±
"""

import json
import openai
from openai import OpenAI
from utils.json_parser import parse_model_output
from utils.prompt_loader import get_prompt_loader
from utils.qna_validator import validate_qna


# A.X 4.0 API ì„¤ì •
AX4_API_BASE_URL = "https://guest-api.sktax.chat/v1"
AX4_API_KEY = "sktax-XyeKFrq67ZjS4EpsDlrHHXV8it"
AX4_MODEL = "ax4"

# ì „ì—­ í´ë¼ì´ì–¸íŠ¸ ë³€ìˆ˜ (ì§€ì—° ë¡œë”©)
_client = None


def get_ax4_client():
    """A.X 4.0 API í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì§€ì—° ë¡œë”©)"""
    global _client
    
    if _client is None:
        try:
            print("A.X 4.0 API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
            _client = OpenAI(
                base_url=AX4_API_BASE_URL,
                api_key=AX4_API_KEY
            )
            print("âœ… A.X 4.0 API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ A.X 4.0 API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise
    
    return _client


def generate_with_ax4_api(prompt: str, max_tokens: int = 12288, temperature: float = 0.7, max_retries: int = 5) -> str:
    """A.X 4.0 APIë¥¼ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„± (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    import time
    import random
    
    client = get_ax4_client()
    
    for attempt in range(max_retries):
        try:
            # ì§€ìˆ˜ ë°±ì˜¤í”„ì™€ ì§€í„° ì ìš©
            if attempt > 0:
                backoff_time = (2 ** attempt) + random.uniform(0, 1)
                print(f"   â³ {backoff_time:.1f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„...")
                time.sleep(backoff_time)
            
            print(f"   ğŸ”„ API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries}")
            
            response = client.chat.completions.create(
                model=AX4_MODEL,
                messages=[
                    {"role": "user", "content": prompt}
                ],
                max_tokens=max_tokens,
                temperature=temperature,
                timeout=60.0  # 60ì´ˆ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            error_msg = str(e)
            print(f"   âŒ API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}): {error_msg[:100]}")
            
            # ë§ˆì§€ë§‰ ì‹œë„ì˜€ë‹¤ë©´ ì˜ˆì™¸ë¥¼ ê·¸ëŒ€ë¡œ raise
            if attempt == max_retries - 1:
                raise e
            
            # íƒ€ì„ì•„ì›ƒì´ë‚˜ ì„œë²„ ì˜¤ë¥˜ì¸ ê²½ìš° ì¬ì‹œë„
            if any(keyword in error_msg.lower() for keyword in 
                   ['timeout', 'timed out', '504', '502', '503', 'gateway', 'server error', 'request timeout']):
                print(f"   ğŸ”„ íƒ€ì„ì•„ì›ƒ/ì„œë²„ ì˜¤ë¥˜ ê°ì§€ - ì¬ì‹œë„ ì˜ˆì •")
                continue
            else:
                # ì§„ì§œ í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ (4xx, ì¸ì¦ ì˜¤ë¥˜ ë“±)ëŠ” ì¬ì‹œë„í•˜ì§€ ì•ŠìŒ
                if any(keyword in error_msg.lower() for keyword in ['401', '403', '400', 'unauthorized', 'forbidden']):
                    print(f"   âŒ í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜ - ì¬ì‹œë„ ì¤‘ë‹¨")
                    raise e
                else:
                    # í™•ì‹¤í•˜ì§€ ì•Šì€ ì˜¤ë¥˜ëŠ” ì¬ì‹œë„
                    print(f"   ğŸ”„ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ - ì¬ì‹œë„ ì˜ˆì •")
                    continue


def generate_artwork_questions_visitor_batch(artwork: dict, fast_mode: bool = True, exclude_instructions: set = None, batch_size: int = 10) -> list:
    """ì‘í’ˆì— ê´€í•œ ì§ˆë¬¸ - ì¼ë°˜ ê´€ëŒê° ê´€ì  (ë°°ì¹˜ í¬ê¸° ì¡°ì • ê°€ëŠ¥)"""
    
    prompt_loader = get_prompt_loader()
    
    # ë°°ì¹˜ í¬ê¸°ì— ë§ì¶° í”„ë¡¬í”„íŠ¸ ì¡°ì •
    original_prompt = prompt_loader.format_visitor_prompt(artwork, exclude_instructions)
    adjusted_prompt = original_prompt.replace("30ê°œ", f"{batch_size}ê°œ")
    
    print(f"   ğŸ“ ì¼ë°˜ ê´€ëŒê° í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(adjusted_prompt)} ë¬¸ì, {batch_size}ê°œ ëª©í‘œ)")
    
    # API ìµœì í™” ì„¤ì • (ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼ í† í° ìˆ˜ ì¡°ì •) - ë” ë³´ìˆ˜ì ìœ¼ë¡œ
    max_tokens = min(4000, batch_size * 250)  # ë°°ì¹˜ë‹¹ ì•½ 250í† í° (ë” ì‘ê²Œ)
    temperature = 0.7 if fast_mode else 0.8
    mode_str = "âš¡ ê³ ì† ëª¨ë“œ" if fast_mode else "ğŸ¯ ì •ë°€ ëª¨ë“œ"
    print(f"   {mode_str} (max_tokens: {max_tokens})")
    
    response = generate_with_ax4_api(
        prompt=adjusted_prompt,
        max_tokens=max_tokens,
        temperature=temperature,
        max_retries=4  # ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì¶©ë¶„í•œ ì¬ì‹œë„
    )
    
    parsed_result = parse_model_output(response, "AX4_API_Visitor_Batch")
    if parsed_result and isinstance(parsed_result, list):
        if len(parsed_result) < batch_size // 2:  # ëª©í‘œì˜ ì ˆë°˜ ì´ìƒ
            print(f"   âš ï¸ ìƒì„± ë¶€ì¡±: {len(parsed_result)}/{batch_size}ê°œ")
        return parsed_result
    return []


def generate_artwork_questions_visitor(artwork: dict, fast_mode: bool = True, exclude_instructions: set = None) -> list:
    """ì‘í’ˆì— ê´€í•œ ì§ˆë¬¸ - ì¼ë°˜ ê´€ëŒê° ê´€ì  (30ê°œ)"""
    
    prompt_loader = get_prompt_loader()
    prompt = prompt_loader.format_visitor_prompt(artwork, exclude_instructions)
    
    print(f"   ğŸ“ ì¼ë°˜ ê´€ëŒê° í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(prompt)} ë¬¸ì)")
    
    # API ìµœì í™” ì„¤ì •
    max_tokens = 12288 if fast_mode else 16384
    temperature = 0.7 if fast_mode else 0.8
    mode_str = "âš¡ ê³ ì† ëª¨ë“œ" if fast_mode else "ğŸ¯ ì •ë°€ ëª¨ë“œ"
    print(f"   {mode_str}")
    
    response = generate_with_ax4_api(
        prompt=prompt,
        max_tokens=max_tokens,
        temperature=temperature
    )
    
    parsed_result = parse_model_output(response, "AX4_API_Visitor")
    if parsed_result and isinstance(parsed_result, list):
        if len(parsed_result) < 20:  # 30ê°œ ëª©í‘œ ì¤‘ ìµœì†Œ 20ê°œëŠ” ìˆì–´ì•¼ í•¨
            print(f"   âš ï¸ ìƒì„± ë¶€ì¡±: {len(parsed_result)}/30ê°œ - ì¬ì‹œë„ ê¶Œì¥")
        return parsed_result
    return []


def generate_artwork_questions_curator_batch(artwork: dict, fast_mode: bool = True, exclude_instructions: set = None, batch_size: int = 10) -> list:
    """ì‘í’ˆì— ê´€í•œ ì§ˆë¬¸ - íë ˆì´í„°/ê³µì˜ˆì´ë¡ ê°€ ê´€ì  (ë°°ì¹˜ í¬ê¸° ì¡°ì • ê°€ëŠ¥)"""
    
    prompt_loader = get_prompt_loader()
    
    # ë°°ì¹˜ í¬ê¸°ì— ë§ì¶° í”„ë¡¬í”„íŠ¸ ì¡°ì •
    original_prompt = prompt_loader.format_curator_artwork_prompt(artwork, exclude_instructions)
    adjusted_prompt = original_prompt.replace("30ê°œ", f"{batch_size}ê°œ")
    
    print(f"   ğŸ“ íë ˆì´í„° ì‘í’ˆ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(adjusted_prompt)} ë¬¸ì, {batch_size}ê°œ ëª©í‘œ)")
    
    # API ìµœì í™” ì„¤ì • (ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼ í† í° ìˆ˜ ì¡°ì •) - ë” ë³´ìˆ˜ì ìœ¼ë¡œ
    max_tokens = min(4000, batch_size * 250)  # ë°°ì¹˜ë‹¹ ì•½ 250í† í° (ë” ì‘ê²Œ)
    temperature = 0.7 if fast_mode else 0.8
    mode_str = "âš¡ ê³ ì† ëª¨ë“œ" if fast_mode else "ğŸ¯ ì •ë°€ ëª¨ë“œ"
    print(f"   {mode_str} (max_tokens: {max_tokens})")
    
    response = generate_with_ax4_api(
        prompt=adjusted_prompt,
        max_tokens=max_tokens,
        temperature=temperature,
        max_retries=4  # ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì¶©ë¶„í•œ ì¬ì‹œë„
    )
    
    parsed_result = parse_model_output(response, "AX4_API_Curator_Batch")
    if parsed_result and isinstance(parsed_result, list):
        if len(parsed_result) < batch_size // 2:  # ëª©í‘œì˜ ì ˆë°˜ ì´ìƒ
            print(f"   âš ï¸ ìƒì„± ë¶€ì¡±: {len(parsed_result)}/{batch_size}ê°œ")
        return parsed_result
    return []


def generate_artwork_questions_curator(artwork: dict, fast_mode: bool = True, exclude_instructions: set = None) -> list:
    """ì‘í’ˆì— ê´€í•œ ì§ˆë¬¸ - íë ˆì´í„°/ê³µì˜ˆì´ë¡ ê°€ ê´€ì  (30ê°œ)"""
    
    prompt_loader = get_prompt_loader()
    prompt = prompt_loader.format_curator_artwork_prompt(artwork, exclude_instructions)
    
    print(f"   ğŸ“ íë ˆì´í„° ì‘í’ˆ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(prompt)} ë¬¸ì)")
    
    # API ìµœì í™” ì„¤ì •
    max_tokens = 12288 if fast_mode else 16384
    temperature = 0.7 if fast_mode else 0.8
    mode_str = "âš¡ ê³ ì† ëª¨ë“œ" if fast_mode else "ğŸ¯ ì •ë°€ ëª¨ë“œ"
    print(f"   {mode_str}")
    
    response = generate_with_ax4_api(
        prompt=prompt,
        max_tokens=max_tokens,
        temperature=temperature
    )
    
    parsed_result = parse_model_output(response, "AX4_API_Curator")
    if parsed_result and isinstance(parsed_result, list):
        if len(parsed_result) < 20:  # 30ê°œ ëª©í‘œ ì¤‘ ìµœì†Œ 20ê°œëŠ” ìˆì–´ì•¼ í•¨
            print(f"   âš ï¸ ìƒì„± ë¶€ì¡±: {len(parsed_result)}/30ê°œ - ì¬ì‹œë„ ê¶Œì¥")
        return parsed_result
    return []


def generate_artist_questions_curator_batch(artwork: dict, fast_mode: bool = True, exclude_instructions: set = None, batch_size: int = 10) -> list:
    """ì‘ê°€ì— ëŒ€í•œ ì§ˆë¬¸ - íë ˆì´í„°/ê³µì˜ˆì´ë¡ ê°€ ê´€ì  (ë°°ì¹˜ í¬ê¸° ì¡°ì • ê°€ëŠ¥)"""
    
    prompt_loader = get_prompt_loader()
    
    # ë°°ì¹˜ í¬ê¸°ì— ë§ì¶° í”„ë¡¬í”„íŠ¸ ì¡°ì •
    original_prompt = prompt_loader.format_curator_artist_prompt(artwork, exclude_instructions)
    adjusted_prompt = original_prompt.replace("20ê°œ", f"{batch_size}ê°œ")
    
    print(f"   ğŸ“ íë ˆì´í„° ì‘ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(adjusted_prompt)} ë¬¸ì, {batch_size}ê°œ ëª©í‘œ)")
    
    # ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼ í† í° ìˆ˜ ì¡°ì • (ì‘ê°€ ì§ˆë¬¸ì€ ì¢€ ë” ê¸¸ ìˆ˜ ìˆìŒ) - ë³´ìˆ˜ì ìœ¼ë¡œ
    max_tokens = min(5000, batch_size * 300)  # ë°°ì¹˜ë‹¹ ì•½ 300í† í° (ë” ì‘ê²Œ)
    temperature = 0.8  # ì‘ê°€ ì§ˆë¬¸ì€ ì¢€ ë” ë‹¤ì–‘ì„± í•„ìš”
    print(f"   ğŸ¯ ì‘ê°€ ê´€ì  ëª¨ë“œ (max_tokens: {max_tokens})")
    
    response = generate_with_ax4_api(
        prompt=adjusted_prompt,
        max_tokens=max_tokens,
        temperature=temperature,
        max_retries=4  # ë°°ì¹˜ ì²˜ë¦¬ ì‹œ ì¶©ë¶„í•œ ì¬ì‹œë„
    )
    
    parsed_result = parse_model_output(response, "AX4_API_Artist_Batch")
    if parsed_result and isinstance(parsed_result, list):
        if len(parsed_result) < batch_size // 2:  # ëª©í‘œì˜ ì ˆë°˜ ì´ìƒ
            print(f"   âš ï¸ ìƒì„± ë¶€ì¡±: {len(parsed_result)}/{batch_size}ê°œ")
        return parsed_result
    return []


def generate_artist_questions_curator(artwork: dict, fast_mode: bool = True, exclude_instructions: set = None) -> list:
    """ì‘ê°€ì— ëŒ€í•œ ì§ˆë¬¸ - íë ˆì´í„°/ê³µì˜ˆì´ë¡ ê°€ ê´€ì  (20ê°œ)"""
    
    prompt_loader = get_prompt_loader()
    prompt = prompt_loader.format_curator_artist_prompt(artwork, exclude_instructions)
    
    print(f"   ğŸ“ íë ˆì´í„° ì‘ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ ({len(prompt)} ë¬¸ì)")
    
    # ê³ í’ˆì§ˆ ëª¨ë“œ ê°•ì œ ì ìš© (20ê°œ ì™„ì „ ìƒì„±ì„ ìœ„í•´)
    max_tokens = 16384  # ì¶©ë¶„í•œ í† í° í• ë‹¹
    temperature = 0.8  # ë” ë†’ì€ ë‹¤ì–‘ì„±ê³¼ ì™„ì„±ë„
    print("   ğŸ¯ ê³ í’ˆì§ˆ ëª¨ë“œ í™œì„±í™” (20ê°œ ì™„ì „ ìƒì„±)")
    
    response = generate_with_ax4_api(
        prompt=prompt,
        max_tokens=max_tokens,
        temperature=temperature
    )
    
    parsed_result = parse_model_output(response, "AX4_API_Artist")
    if parsed_result and isinstance(parsed_result, list):
        if len(parsed_result) < 15:  # 20ê°œ ëª©í‘œ ì¤‘ ìµœì†Œ 15ê°œëŠ” ìˆì–´ì•¼ í•¨
            print(f"   âš ï¸ ìƒì„± ë¶€ì¡±: {len(parsed_result)}/20ê°œ - ì¬ì‹œë„ ê¶Œì¥")
        return parsed_result
    return []


def generate_all_qa_batch(artwork: dict, fast_mode: bool = True, exclude_questions: list = None) -> str:
    """ëª¨ë“  ìœ í˜•ì˜ Q&Aë¥¼ ë°°ì¹˜ë¡œ ìƒì„± (íƒ€ì„ì•„ì›ƒ ë°©ì§€ë¥¼ ìœ„í•œ ìˆœì°¨ ì²˜ë¦¬)"""
    import time
    
    mode_str = "âš¡ ê³ ì† ëª¨ë“œ" if fast_mode else "ğŸ¯ ì •ë°€ ëª¨ë“œ"
    print(f"   ğŸ“Š {mode_str}ë¡œ Q&A ìƒì„± ì‹œì‘ (ìˆœì°¨ ì²˜ë¦¬)")
    
    # ê¸°ì¡´ ì§ˆë¬¸ ì •ë³´ ì²˜ë¦¬
    exclude_instructions = set()
    if exclude_questions:
        for q in exclude_questions:
            instruction = q.get('instruction', '').strip().lower()
            exclude_instructions.add(instruction)
        print(f"   âš ï¸ ì œì™¸í•  ê¸°ì¡´ ì§ˆë¬¸: {len(exclude_instructions)}ê°œ")
    
    all_qa = []
    
    # ë” ì‘ì€ ë°°ì¹˜ë¡œ ì„¸ë¶„í™” (10ê°œì”© 8ë‹¨ê³„)
    batches = [
        ("ì¼ë°˜ ê´€ëŒê° 1ì°¨", "visitor", 10),
        ("ì¼ë°˜ ê´€ëŒê° 2ì°¨", "visitor", 10), 
        ("ì¼ë°˜ ê´€ëŒê° 3ì°¨", "visitor", 10),
        ("íë ˆì´í„° ì‘í’ˆ 1ì°¨", "curator_artwork", 10),
        ("íë ˆì´í„° ì‘í’ˆ 2ì°¨", "curator_artwork", 10),
        ("íë ˆì´í„° ì‘í’ˆ 3ì°¨", "curator_artwork", 10),
        ("íë ˆì´í„° ì‘ê°€ 1ì°¨", "curator_artist", 10),
        ("íë ˆì´í„° ì‘ê°€ 2ì°¨", "curator_artist", 10),
    ]
    
    for i, (batch_name, batch_type, batch_size) in enumerate(batches, 1):
        print(f"   ğŸ“ [{i}/8] {batch_name} ì§ˆë¬¸ ìƒì„± ì¤‘... ({batch_size}ê°œ)")
        try:
            if batch_type == "visitor":
                qa_batch = generate_artwork_questions_visitor_batch(artwork, fast_mode, exclude_instructions, batch_size=batch_size)
            elif batch_type == "curator_artwork":
                qa_batch = generate_artwork_questions_curator_batch(artwork, fast_mode, exclude_instructions, batch_size=batch_size)
            else:  # curator_artist
                qa_batch = generate_artist_questions_curator_batch(artwork, fast_mode, exclude_instructions, batch_size=batch_size)
            
            print(f"   âœ… {batch_name}: {len(qa_batch)}ê°œ ìƒì„±")
            all_qa.extend(qa_batch)
            
            # ë°°ì¹˜ ê°„ ë” ê¸´ ëŒ€ê¸°ì‹œê°„
            if i < len(batches):  # ë§ˆì§€ë§‰ ë°°ì¹˜ê°€ ì•„ë‹ˆë©´
                print(f"   â³ ë‹¤ìŒ ë°°ì¹˜ê¹Œì§€ 3ì´ˆ ëŒ€ê¸°...")
                time.sleep(3)
                
        except Exception as e:
            print(f"   âš ï¸ {batch_name} ìƒì„± ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
    
    total_count = len(all_qa)
    print(f"   ğŸ“Š ì´ ìƒì„±ëœ Q&A: {total_count}ê°œ")
    
    if total_count < 50:  # ìµœì†Œ ê¸°ì¤€ì„ ë‚®ì¶¤ (íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¸í•œ ë¶€ë¶„ ì‹¤íŒ¨ ê³ ë ¤)
        print(f"   âš ï¸ ìƒì„±ëœ Q&Aê°€ ë¶€ì¡±í•©ë‹ˆë‹¤: {total_count}/80ê°œ (ëª©í‘œ)")
    
    # ê²°ê³¼ë¥¼ ê²€ì¦í•˜ê³  ë°˜í™˜
    validated_items = validate_qna(all_qa)
    
    print(f"   âœ… ê²€ì¦ ì™„ë£Œ: {len(validated_items)}ê°œ ìœ íš¨í•œ Q&A")
    return json.dumps(validated_items, ensure_ascii=False, indent=2)


# ê¸°ì¡´ í•¨ìˆ˜ë“¤ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ wrapper
def generate_qa_batch(model_tokenizer_tuple, artwork: dict) -> str:
    """ë°°ì¹˜ ì²˜ë¦¬ìš© wrapper í•¨ìˆ˜ (APIì—ì„œëŠ” model_tokenizer_tuple ë¶ˆí•„ìš”)"""
    return generate_all_qa_batch(artwork)


def generate_qa_directly(artwork: dict) -> str:
    """APIë¥¼ ì§ì ‘ ì‚¬ìš©í•´ì„œ Q&A ìƒì„±"""
    return generate_all_qa_batch(artwork)